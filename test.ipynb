{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "world = client.get_world()\n",
    "world_map = world.get_map()\n",
    "spawn_points = world_map.get_spawn_points()\n",
    "start_point = spawn_points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blueprint of a black car \n",
    "blueprint_library = world.get_blueprint_library()\n",
    "vehicle_bp = random.choice(blueprint_library.filter('vehicle.toyota.prius'))\n",
    "vehicle_bp.set_attribute('color', '0,0,0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn a vehicle on where I am looking at\n",
    "\n",
    "# first get where I am looking at\n",
    "# spectator = world.get_spectator()\n",
    "# spectator_transform = spectator.get_transform()\n",
    "# location = spectator_transform.location\n",
    "# rotation = spectator_transform.rotation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# distance_ahead = 10  # Spawn the car 10 meters in front\n",
    "# yaw = math.radians(rotation.yaw)  # Convert yaw to radians\n",
    "\n",
    "# spawn_location = carla.Location(\n",
    "#     x=location.x + distance_ahead * math.cos(yaw),\n",
    "#     y=location.y + distance_ahead * math.sin(yaw),\n",
    "#     z=location.z  # Keep the Z-height same (adjust if needed)\n",
    "# )\n",
    "\n",
    "# vehicle = world.try_spawn_actor(vehicle_bp, start_point)h\n",
    "# spawn_transform = carla.Transform(spawn_location, rotation)\n",
    "# jake = world.try_spawn_actor(vehicle_bp, spawn_transform)\n",
    "\n",
    "# Spawn the vehicle\n",
    "# jake = world.try_spawn_actor(vehicle_bp, spawn_transform)\n",
    "# Spawn a vehicle on where I am looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Spawn failed because of collision at spawn position",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m jake_transform \u001b[38;5;241m=\u001b[39m carla\u001b[38;5;241m.\u001b[39mTransform(jake_location, jake_rotation)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Spawn the camera at the spectator's position and orientation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m jake \u001b[38;5;241m=\u001b[39m \u001b[43mworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvehicle_bp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjake_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Spawn failed because of collision at spawn position"
     ]
    }
   ],
   "source": [
    "# spawn jake at the left side of the parking lot \n",
    "\n",
    "jake_location = carla.Location(x=-58.468666, y=188.412048, z=0.1)\n",
    "jake_rotation = carla.Rotation(pitch=0, yaw=-90, roll=0) \n",
    "\n",
    "jake_transform = carla.Transform(jake_location, jake_rotation)\n",
    "# Spawn the camera at the spectator's position and orientation\n",
    "jake = world.spawn_actor(vehicle_bp, jake_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spawn a BEV camera and segment stuff using deeplabv3\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "# model.eval()\n",
    "# COLORS = np.array([\n",
    "#     [255, 0, 0], [0, 255, 0], [0, 0, 255], [128, 128, 0], [128, 0, 128], [0, 128, 128], \n",
    "#     [128, 64, 64], [64, 128, 128], [64, 128, 64], [64, 64, 196], [196, 128, 0], [196, 128, 196],\n",
    "#     # Add more colors as needed for other classes\n",
    "# ])\n",
    "\n",
    "# # create the BEV camera above the parking lot \n",
    "# camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "# camera_bp.set_attribute('image_size_x', '800')\n",
    "# camera_bp.set_attribute('image_size_y', '600')\n",
    "# camera_bp.set_attribute('fov', '90')  # Adjust FOV if needed\n",
    "# camera_bp.set_attribute('sensor_tick', '3.0')\n",
    "# bev_location = carla.Location(x=-58.686981, y=166.857986, z=24.152607) \n",
    "# spectator_rotation = carla.Rotation(pitch=-90, yaw=-180, roll=0) \n",
    "\n",
    "# # Create a transform using the given location and rotation\n",
    "# bev_transform = carla.Transform(bev_location, spectator_rotation)\n",
    "# # Spawn the camera at the spectator's position and orientation\n",
    "# camera = world.spawn_actor(camera_bp, bev_transform)\n",
    "\n",
    "# def process_image(image):\n",
    "#     array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "#     array = array.reshape((image.height, image.width, 4))  # Convert to 2D array\n",
    "#     image_rgb = array[:, :, :3]  # Discard the alpha channel\n",
    "\n",
    "#     # Preprocess image for DeepLabv3 (resize and normalize)\n",
    "#     input_image = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "#     input_image = torch.tensor(input_image).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "\n",
    "#     # Run the model on the image\n",
    "#     with torch.no_grad():\n",
    "#         output = model(input_image)['out'][0]  # Get model's output\n",
    "#     output_predictions = output.argmax(0)  # Get the class predictions (highest logit)\n",
    "    \n",
    "#     # Convert the predictions to colors\n",
    "#     seg_image = COLORS[output_predictions.numpy()]\n",
    "    \n",
    "#     # Create the masked image by blending the segmentation output with the original image\n",
    "#     masked_image = np.copy(image_rgb)\n",
    "#     masked_image[output_predictions.numpy() == 0] = [0, 0, 0]  # Optionally mask out background (class 0)\n",
    "\n",
    "#     # Overlay the segmentation result on the original image\n",
    "#     blended_image = cv2.addWeighted(image_rgb, 0.7, seg_image.astype(np.uint8), 0.3, 0)\n",
    "#     unique_values = np.unique(output_predictions)\n",
    "#     # Display the result\n",
    "#     cv2.imshow(\"BEV + Segmentation\", blended_image)\n",
    "#     cv2.waitKey(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spawn a camera in front of jake and do segmenation using YOLO\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import threading\n",
    "# # from yolo import *\n",
    "# from ultralytics import YOLO\n",
    "# seg_model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "\n",
    "# # create the BEV camera above the parking lot \n",
    "# camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "# camera_bp.set_attribute('image_size_x', '800')\n",
    "# camera_bp.set_attribute('image_size_y', '600')\n",
    "# camera_bp.set_attribute('fov', '90')  # Adjust FOV if needed\n",
    "# # camera_bp.set_attribute('sensor_tick', '5.0')\n",
    "# camera_transform = carla.Transform(carla.Location(x=0, y=5, z=2))  # Adjust if needed\n",
    "\n",
    "# camera = world.spawn_actor(camera_bp, camera_transform, attach_to=jake)\n",
    "\n",
    "# def process_image(image):\n",
    "#     array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "#     array = array.reshape((image.height, image.width, 4))  # Convert to 2D array\n",
    "#     array = array[:, :, :3]  # Remove alpha channel\n",
    "#     results = seg_model(array)  # Perform inference\n",
    "#     annotated_frame = results[0].plot()  # Get the annotated image\n",
    "#     cv2.imshow(\"BEV + Segmentation\", annotated_frame)\n",
    "    \n",
    "#     # Check if window is closed\n",
    "#     # key = cv2.waitKey(1) & 0xFF\n",
    "#     # if cv2.getWindowProperty(\"BEV + Segmentation\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "#     #     running = False\n",
    "#     #     camera.stop()\n",
    "#     #     cv2.destroyAllWindows()\n",
    "\n",
    "#     cv2.waitKey(1)\n",
    "# camera.listen(lambda image: process_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in N:\\windat.v2/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Spawn a camera in front of jake and do segmenation using DeepLabv3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import threading \n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "model.eval()\n",
    "COLORS = np.array([\n",
    "    [255, 0, 0], [0, 255, 0], [0, 0, 255], [128, 128, 0], [128, 0, 128], [0, 128, 128], \n",
    "    [128, 64, 64], [64, 128, 128], [64, 128, 64], [64, 64, 196], [196, 128, 0], [196, 128, 196],\n",
    "    # Add more colors as needed for other classes\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# create the BEV camera above the parking lot \n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '800')\n",
    "camera_bp.set_attribute('image_size_y', '600')\n",
    "camera_bp.set_attribute('fov', '90')  # Adjust FOV if needed\n",
    "# camera_bp.set_attribute('sensor_tick', '1.0')\n",
    "camera_bp.set_attribute('sensor_tick', '0.033333')  # 30 FPS \n",
    "# camera_bp.set_attribute('sensor_tick', '5.0')\n",
    "camera_transform = carla.Transform(carla.Location(x=0, y=0, z=2))  # Adjust if needed\n",
    "\n",
    "camera = world.spawn_actor(camera_bp, camera_transform, attach_to=jake)\n",
    "\n",
    "def process_image(image):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))  # Convert to 2D array\n",
    "    image_rgb = array[:, :, :3]  # Discard the alpha channel\n",
    "\n",
    "    # Preprocess image for DeepLabv3 (resize and normalize)\n",
    "    input_image = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "    input_image = torch.tensor(input_image).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "\n",
    "    # Run the model on the image\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)['out'][0]  # Get model's output\n",
    "    output_predictions = output.argmax(0)  # Get the class predictions (highest logit)\n",
    "    \n",
    "    # Convert the predictions to colors\n",
    "    seg_image = COLORS[output_predictions.numpy()]\n",
    "    \n",
    "    # Create the masked image by blending the segmentation output with the original image\n",
    "    masked_image = np.copy(image_rgb)\n",
    "    masked_image[output_predictions.numpy() == 0] = [0, 0, 0]  # Optionally mask out background (class 0)\n",
    "\n",
    "    # Overlay the segmentation result on the original image\n",
    "    blended_image = cv2.addWeighted(image_rgb, 0.7, seg_image.astype(np.uint8), 0.3, 0)\n",
    "    # unique_values = np.unique(output_predictions)\n",
    "    # Display the result\n",
    "    display_queue.put(blended_image)\n",
    "    # cv2.imshow(\"POV + Segmentation\", blended_image)\n",
    "\n",
    "    # cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# normal display without segmentation \n",
    "def process_image(image):\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image.raw_data)\n",
    "    image_array = image_array.reshape((image.height, image.width, 4))  # Change to a 3D array (height, width, RGBA)\n",
    "\n",
    "    # Convert to BGR (OpenCV format)\n",
    "    image_bgr = image_array[:, :, :3]\n",
    "\n",
    "    # Use a queue to safely pass images to the display thread\n",
    "    display_queue.put(image_bgr)\n",
    "\n",
    "def display_image():\n",
    "    while True:\n",
    "        # Check if the queue has a new image to display\n",
    "        if not display_queue.empty():\n",
    "            image_bgr = display_queue.get()\n",
    "            cv2.imshow('RGB Cam + Segmentation', image_bgr)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "# Start the display thread\n",
    "import queue\n",
    "display_queue = queue.Queue()\n",
    "\n",
    "display_thread = threading.Thread(target=display_image)\n",
    "display_thread.daemon = True\n",
    "display_thread.start()\n",
    "\n",
    "camera.listen(lambda image: threading.Thread(target=process_image, args=(image,)).start())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jake.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'PolyData'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 105\u001b[0m\n\u001b[0;32m    101\u001b[0m lidar_transform \u001b[38;5;241m=\u001b[39m carla\u001b[38;5;241m.\u001b[39mTransform(carla\u001b[38;5;241m.\u001b[39mLocation(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# Adjust if needed\u001b[39;00m\n\u001b[0;32m    103\u001b[0m lidar \u001b[38;5;241m=\u001b[39m world\u001b[38;5;241m.\u001b[39mspawn_actor(lidar_bp, lidar_transform, attach_to\u001b[38;5;241m=\u001b[39mjake)\n\u001b[1;32m--> 105\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mmlab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m960\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m540\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbgcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m vis \u001b[38;5;241m=\u001b[39m mlab\u001b[38;5;241m.\u001b[39mpoints3d(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoint\u001b[39m\u001b[38;5;124m'\u001b[39m, figure\u001b[38;5;241m=\u001b[39mfig)\n\u001b[0;32m    107\u001b[0m mlab\u001b[38;5;241m.\u001b[39mview(distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\mayavi\\tools\\figure.py:69\u001b[0m, in \u001b[0;36mfigure\u001b[1;34m(figure, bgcolor, fgcolor, engine, size)\u001b[0m\n\u001b[0;32m     67\u001b[0m     __scene_number_list\u001b[38;5;241m.\u001b[39mupdate((name,))\n\u001b[0;32m     68\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMayavi Scene \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_scene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     engine\u001b[38;5;241m.\u001b[39mcurrent_scene\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\apptools\\scripting\\recordable.py:48\u001b[0m, in \u001b[0;36mrecordable.<locals>._wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     45\u001b[0m             _outermost_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m record:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# If the method was not recorded, just call it.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\mayavi\\core\\engine.py:452\u001b[0m, in \u001b[0;36mEngine.new_scene\u001b[1;34m(self, viewer, name, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m factory_kwargs_names:\n\u001b[0;32m    450\u001b[0m             factory_kwargs[arg] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 452\u001b[0m     viewer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscene_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m     process_ui_events()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\mayavi\\core\\ui\\mayavi_scene.py:89\u001b[0m, in \u001b[0;36mviewer_factory\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m     87\u001b[0m viewer\u001b[38;5;241m.\u001b[39mmenu_bar_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     88\u001b[0m viewer\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m=\u001b[39msize\n\u001b[1;32m---> 89\u001b[0m \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m viewer\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\pyface\\i_window.py:231\u001b[0m, in \u001b[0;36mMWindow.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event\u001b[38;5;241m.\u001b[39mveto:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m# Create the control, if necessary.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\pyface\\ui\\qt\\application_window.py:111\u001b[0m, in \u001b[0;36mApplicationWindow.create\u001b[1;34m(self, parent)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(parent\u001b[38;5;241m=\u001b[39mparent)\n\u001b[1;32m--> 111\u001b[0m     contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39msetCentralWidget(contents)\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_trim_widgets(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\tools\\ivtk.py:406\u001b[0m, in \u001b[0;36mIVTK._create_contents\u001b[1;34m(self, parent)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_contents\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent):\n\u001b[0;32m    404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Create the contents of the window. \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscene \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scene_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscene\u001b[38;5;241m.\u001b[39mcontrol\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\mayavi\\core\\ui\\mayavi_scene.py:68\u001b[0m, in \u001b[0;36mmayavi_scene_factory\u001b[1;34m(parent)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A mayavi scene factory that creates a scene with preferences\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03mappropriately set.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m p \u001b[38;5;241m=\u001b[39m get_scene_preferences()\n\u001b[1;32m---> 68\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mMayaviScene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstereo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstereo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m set_scene_preferences(s, p)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\pyface\\ui\\qt4\\decorated_scene.py:57\u001b[0m, in \u001b[0;36mDecoratedScene.__init__\u001b[1;34m(self, parent, **traits)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtraits):\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDecoratedScene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_axes_marker()\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\pyface\\ui\\qt4\\scene.py:336\u001b[0m, in \u001b[0;36mScene.__init__\u001b[1;34m(self, parent, **traits)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28msuper\u001b[39m(Scene, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(parent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtraits)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Setup the default picker.\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpicker \u001b[38;5;241m=\u001b[39m \u001b[43mpicker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPicker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# The light manager needs creating.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlight_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\pyface\\picker.py:276\u001b[0m, in \u001b[0;36mPicker.__init__\u001b[1;34m(self, renwin, **traits)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcellpicker \u001b[38;5;241m=\u001b[39m tvtk\u001b[38;5;241m.\u001b[39mCellPicker()\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworldpicker \u001b[38;5;241m=\u001b[39m tvtk\u001b[38;5;241m.\u001b[39mWorldPointPicker()\n\u001b[1;32m--> 276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe_data \u001b[38;5;241m=\u001b[39m \u001b[43mtvtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPolyData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Use a set of axis to show the picked point.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_source \u001b[38;5;241m=\u001b[39m tvtk\u001b[38;5;241m.\u001b[39mAxes()\n",
      "File \u001b[1;32mtvtk_classes\\poly_data.py:88\u001b[0m, in \u001b[0;36mPolyData.__init__\u001b[1;34m(self, obj, update, **traits)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtraits):\n\u001b[1;32m---> 88\u001b[0m     \u001b[43mtvtk_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTVTKBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvtkPolyData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\tvtk_base.py:435\u001b[0m, in \u001b[0;36mTVTKBase.__init__\u001b[1;34m(self, klass, obj, update, **traits)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_traits()\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Setup observers for the modified event.\u001b[39;00m\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_observers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m _object_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vtk_obj\u001b[38;5;241m.\u001b[39m__this__] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\tvtk_base.py:536\u001b[0m, in \u001b[0;36mTVTKBase.setup_observers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup_observers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    533\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add an observer for the ModifiedEvent so the traits are kept\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;124;03m    up-to-date with the wrapped VTK object and do it in a way that\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;124;03m    avoids reference cycles.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m     \u001b[43m_object_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_observers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vtk_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModifiedEvent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_traits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\tvtk_base.py:93\u001b[0m, in \u001b[0;36mTVTKObjectCache.setup_observers\u001b[1;34m(self, vtk_obj, event, method)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Setup the observer so the traits are updated even if the\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# wrapped VTK object changes.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(vtk_obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddObserver\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Some classes like vtkInformation* derive from\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# tvtk.ObjectBase which don't support Add/RemoveObserver.\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mmessenger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvtk_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     ob_id \u001b[38;5;241m=\u001b[39m vtk_obj\u001b[38;5;241m.\u001b[39mAddObserver(event, messenger\u001b[38;5;241m.\u001b[39msend)\n\u001b[0;32m     95\u001b[0m     key \u001b[38;5;241m=\u001b[39m vtk_obj\u001b[38;5;241m.\u001b[39m__this__\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\messenger.py:302\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(obj, event, callback)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(obj, event, callback):\n\u001b[1;32m--> 302\u001b[0m     \u001b[43m_messenger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mn:\\windat.v2\\Desktop\\rob530\\CARLA_0.9.15\\WindowsNoEditor\\PythonAPI\\examples\\myenv\\lib\\site-packages\\tvtk\\messenger.py:148\u001b[0m, in \u001b[0;36mMessenger.connect\u001b[1;34m(self, obj, event, callback)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Registers a slot given an object and its signal to slot\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03minto and also given a bound method in `callback` that should\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mhave two arguments.  `send` will call the callback\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(callback)\n\u001b[1;32m--> 148\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signals:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signals[key] \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'PolyData'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import threading\n",
    "import numpy as np\n",
    "from mayavi import mlab\n",
    "\n",
    "\n",
    "def lidar_callback(point_cloud, buf):\n",
    "    \"\"\"Prepares a point cloud with intensity colors and stores in a buffer, which updated the mayavi visualisation\"\"\"\n",
    "    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4')))\n",
    "    data = np.reshape(data, (int(data.shape[0] / 4), 4))\n",
    "\n",
    "    # Isolate the intensity and compute a color for it\n",
    "    intensity = data[:, -1]\n",
    "    intensity_col = 1.0 - np.log(intensity) / np.log(np.exp(-0.004 * 100))\n",
    "\n",
    "    # Isolate the 3D data\n",
    "    points = data[:, :-1]\n",
    "\n",
    "    # We're negating the y to correclty visualize a world that matches\n",
    "    # what we see in Unreal since Mayavi uses a right-handed coordinate system\n",
    "    points[:, :1] = -points[:, :1]\n",
    "\n",
    "    # # An example of converting points from sensor to vehicle space if we had\n",
    "    # # a carla.Transform variable named \"tran\":\n",
    "    # points = np.append(points, np.ones((points.shape[0], 1)), axis=1)\n",
    "    # points = np.dot(tran.get_matrix(), points.T).T\n",
    "    # points = points[:, :-1]\n",
    "\n",
    "    #copy points/intensities into buffer\n",
    "    buf['pts'] = points\n",
    "    buf['intensity'] = intensity\n",
    "\n",
    "def semantic_lidar_callback(point_cloud, buf):\n",
    "    \"\"\"Prepares a point cloud with semantic segmentation colors\"\"\"\n",
    "    data = np.frombuffer(point_cloud.raw_data, dtype=np.dtype([\n",
    "        ('x', np.float32), ('y', np.float32), ('z', np.float32),\n",
    "        ('CosAngle', np.float32), ('ObjIdx', np.uint32), ('ObjTag', np.uint32)]))\n",
    "\n",
    "    # We're negating the y to correclty visualize a world that matches\n",
    "    # what we see in Unreal since Open3D uses a right-handed coordinate system\n",
    "    points = np.array([data['x'], -data['y'], data['z']]).T\n",
    "\n",
    "    # # An example of adding some noise to our data if needed:\n",
    "    # points += np.random.uniform(-0.05, 0.05, size=points.shape)\n",
    "\n",
    "    # Colorize the pointcloud based on the CityScapes color palette\n",
    "    labels = np.array(data['ObjTag'], dtype=np.float32)\n",
    "    int_color = labels\n",
    "\n",
    "    # # In case you want to make the color intensity depending\n",
    "    # # of the incident ray angle, you can use:\n",
    "    #  int_color *= np.array(data['CosAngle'])\n",
    "\n",
    "    buf['pts'] = points\n",
    "    buf['intensity'] = labels\n",
    "\n",
    "\n",
    "def carlaEventLoop(world):\n",
    "        frame = 0\n",
    "        dt0 = datetime.now()\n",
    "        while True:\n",
    "            time.sleep(0.005)\n",
    "            world.tick()\n",
    "\n",
    "            process_time = datetime.now() - dt0\n",
    "            sys.stdout.write('\\r' + 'FPS: ' + str(1.0 / process_time.total_seconds()))\n",
    "            sys.stdout.flush()\n",
    "            dt0 = datetime.now()\n",
    "            frame += 1\n",
    "try:\n",
    "    original_settings = world.get_settings()\n",
    "    settings = world.get_settings()\n",
    "    traffic_manager = client.get_trafficmanager(8000)\n",
    "    traffic_manager.set_synchronous_mode(True)\n",
    "\n",
    "    delta = 0.05\n",
    "\n",
    "    settings.fixed_delta_seconds = delta\n",
    "    settings.synchronous_mode = True\n",
    "    world.apply_settings(settings)\n",
    "    # spawn jake at the left side of the parking lot \n",
    "\n",
    "    jake_location = carla.Location(x=-58.468666, y=188.412048, z=7.642653)\n",
    "    jake_rotation = carla.Rotation(pitch=0, yaw=-90, roll=0) \n",
    "\n",
    "    jake_transform = carla.Transform(jake_location, jake_rotation)\n",
    "    # Spawn the camera at the spectator's position and orientation\n",
    "    jake = world.spawn_actor(vehicle_bp, jake_transform)\n",
    "\n",
    "\n",
    "    jake.set_autopilot(True)\n",
    "\n",
    "    lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')\n",
    "    # lidar_bp.set_attribute('sensor_tick', '5.0')\n",
    "    lidar_transform = carla.Transform(carla.Location(x=0, y=5, z=0))  # Adjust if needed\n",
    "\n",
    "    lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to=jake)\n",
    "\n",
    "    fig = mlab.figure(size=(960,540), bgcolor=(0.05,0.05,0.05))\n",
    "    vis = mlab.points3d(0, 0, 0, 0, mode='point', figure=fig)\n",
    "    mlab.view(distance=25)\n",
    "    buf = {'pts': np.zeros((1,3)), 'intensity':np.zeros(1)}\n",
    "\n",
    "    #  @mlab.animate(delay=100)\n",
    "    def anim():\n",
    "        i=0\n",
    "        while True:\n",
    "            vis.mlab_source.reset(x=buf['pts'][:,0], y=buf['pts'][:,1], z=buf['pts'][:,2], scalars=buf['intensity'])\n",
    "            mlab.savefig(f'{i}.png', figure=fig)\n",
    "            time.sleep(0.1)\n",
    "            i+=1\n",
    "\n",
    "    # lidar.listen(lambda data: semantic_lidar_callback(data, buf))\n",
    "    lidar.listen(lambda data: lidar_callback(data, buf))\n",
    "\n",
    "    loopThread = threading.Thread(target=carlaEventLoop, args=[world], daemon=True)\n",
    "    loopThread.start()\n",
    "    anim()\n",
    "    #  mlab.show()\n",
    "\n",
    "finally:\n",
    "    world.apply_settings(original_settings)\n",
    "    traffic_manager.set_synchronous_mode(False)\n",
    "\n",
    "    jake.destroy()\n",
    "    lidar.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# example code to move the car (jake)\n",
    "\n",
    "control = carla.VehicleControl()\n",
    "control.throttle = 0.5  # Forward speed\n",
    "control.steer = -0.5  # Steering angle to move in the desired direction\n",
    "\n",
    "# Apply the control\n",
    "jake.apply_control(control)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "control.throttle = 0  # No forward speed\n",
    "control.steer = 0  # Straight steering to prevent turning\n",
    "\n",
    "# Apply the control to stop the vehicle\n",
    "jake.apply_control(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "control.throttle = 0.5  # No forward speed\n",
    "control.steer = 0  # Straight steering to prevent turning\n",
    "control.reverse= True\n",
    "# Apply the control to stop the vehicle\n",
    "jake.apply_control(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjake\u001b[49m\u001b[38;5;241m.\u001b[39mdestroy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jake' is not defined"
     ]
    }
   ],
   "source": [
    "jake.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draw_line import *\n",
    "\n",
    "jake_location = carla.Location(x=-58.468666, y=188.412048, z=7.642653)\n",
    "\n",
    "draw_line(world, (-40.468666, 193.412048, 1), (-40.468666, 153.412048, 1))\n",
    "draw_line(world, (-40.468666, 153.412048, 1), (-70.468666, 153.412048, 1))\n",
    "draw_line(world, (-70.468666, 193.412048, 1), (-70.468666, 153.412048, 1))\n",
    "draw_line(world, (-40.468666, 193.412048, 1), (-70.468666, 193.412048, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from car_control_helper import * \n",
    "\n",
    "move_car(jake, steer=-1)\n",
    "time.sleep(1)\n",
    "move_car(jake, steer=0)\n",
    "time.sleep(1)\n",
    "stop_car(jake)\n",
    "# move_car(jake, reverse=True, steer = -1)\n",
    "# time.sleep(1)\n",
    "# stop_car(jake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<carla.libcarla.Actor at 0x217e831d190>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d2e0>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d3c0>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d430>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d4a0>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d510>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d580>,\n",
       " <carla.libcarla.TrafficSign at 0x217e831d5f0>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d660>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d6d0>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d740>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d7b0>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d820>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d890>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d900>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d970>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831d9e0>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831da50>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831dac0>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831db30>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831dba0>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831dc10>,\n",
       " <carla.libcarla.TrafficLight at 0x217e831dc80>,\n",
       " <carla.libcarla.Vehicle at 0x217e831dcf0>,\n",
       " <carla.libcarla.Vehicle at 0x217e831dd60>,\n",
       " <carla.libcarla.Vehicle at 0x217e831ddd0>,\n",
       " <carla.libcarla.Vehicle at 0x217e831de40>,\n",
       " <carla.libcarla.Vehicle at 0x217e831deb0>,\n",
       " <carla.libcarla.Vehicle at 0x217e831df20>,\n",
       " <carla.libcarla.Vehicle at 0x217e831df90>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f040>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f0b0>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f120>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f190>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f200>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f270>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f2e0>,\n",
       " <carla.libcarla.Vehicle at 0x217e831f350>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors = world.get_actors()\n",
    "list(actors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('myenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f1a592b45aed7b53483d35a11bf507f7d58506fcbf288e3ee72faa72e4b3be2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
